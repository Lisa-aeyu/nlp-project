{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/lbeno/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torchutils as tu\n",
    "import json\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchmetrics import Accuracy\n",
    "from torchmetrics.classification import MulticlassConfusionMatrix, MulticlassAveragePrecision\n",
    "from torchmetrics.classification import MulticlassPrecision, MulticlassRecall, MulticlassF1Score\n",
    "from time import time\n",
    "from collections import Counter\n",
    "from typing import Union\n",
    "from dataclasses import dataclass\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from models.lamberts_funcs import data_preprocessing\n",
    "from models.lamberts_funcs import my_padding, train3, logs_dict_multi_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import BertTokenizer\n",
    "\n",
    "#tokenizer = BertTokenizer.from_pretrained('DeepPavlov/rubert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "mystem = Mystem()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>movie_name</th>\n",
       "      <th>review_id</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>grade3</th>\n",
       "      <th>grade10</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>top250</td>\n",
       "      <td>Блеф (1976)</td>\n",
       "      <td>17144</td>\n",
       "      <td>Come Back</td>\n",
       "      <td>2011-09-24</td>\n",
       "      <td>Плакали наши денежки ©</td>\n",
       "      <td>Good</td>\n",
       "      <td>10.0</td>\n",
       "      <td>\\n\"Блеф» — одна из моих самых любимых комедий....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>top250</td>\n",
       "      <td>Блеф (1976)</td>\n",
       "      <td>17139</td>\n",
       "      <td>Stasiki</td>\n",
       "      <td>2008-03-04</td>\n",
       "      <td>None</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\\nАдриано Челентано продолжает радовать нас св...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>top250</td>\n",
       "      <td>Блеф (1976)</td>\n",
       "      <td>17137</td>\n",
       "      <td>Flashman</td>\n",
       "      <td>2007-03-04</td>\n",
       "      <td>None</td>\n",
       "      <td>Good</td>\n",
       "      <td>10.0</td>\n",
       "      <td>\\nНесомненно, это один из великих фильмов 80-х...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>top250</td>\n",
       "      <td>Блеф (1976)</td>\n",
       "      <td>17135</td>\n",
       "      <td>Sergio Tishin</td>\n",
       "      <td>2009-08-17</td>\n",
       "      <td>\" Черное, красное, ерунда это все. Выигрывает ...</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\\nЭта фраза на мой взгляд отражает сюжет несом...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>top250</td>\n",
       "      <td>Блеф (1976)</td>\n",
       "      <td>17151</td>\n",
       "      <td>Фюльгья</td>\n",
       "      <td>2009-08-20</td>\n",
       "      <td>«Он хотел убежать? Да! Блеф, блеф…»</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>7.0</td>\n",
       "      <td>\\n- как пела Земфира, скорее всего, по соверше...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36586</th>\n",
       "      <td>bottom100</td>\n",
       "      <td>Цветок дьявола (2010)</td>\n",
       "      <td>25123</td>\n",
       "      <td>bestiya163</td>\n",
       "      <td>2010-09-23</td>\n",
       "      <td>Ой, ой, ой!</td>\n",
       "      <td>Bad</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\\n      Ну с чего бы начать… Давненько я не пи...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36587</th>\n",
       "      <td>bottom100</td>\n",
       "      <td>Цветок дьявола (2010)</td>\n",
       "      <td>25192</td>\n",
       "      <td>Молка</td>\n",
       "      <td>2010-10-02</td>\n",
       "      <td>Молчаливый мужик на коне…</td>\n",
       "      <td>Bad</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\\n      Можно начать с того, что уже постер к ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36588</th>\n",
       "      <td>bottom100</td>\n",
       "      <td>Цветок дьявола (2010)</td>\n",
       "      <td>25080</td>\n",
       "      <td>jetry</td>\n",
       "      <td>2010-09-16</td>\n",
       "      <td>Это проявилось сегодня ночью.</td>\n",
       "      <td>Good</td>\n",
       "      <td>7.0</td>\n",
       "      <td>\\n      Фильм производства России, поэтому мно...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36589</th>\n",
       "      <td>bottom100</td>\n",
       "      <td>Цветок дьявола (2010)</td>\n",
       "      <td>25088</td>\n",
       "      <td>Alkort</td>\n",
       "      <td>2010-09-16</td>\n",
       "      <td>«Finita la comedia»</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\\n      16 сентября на большие экраны вышел «м...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36590</th>\n",
       "      <td>bottom100</td>\n",
       "      <td>Цветок дьявола (2010)</td>\n",
       "      <td>25149</td>\n",
       "      <td>Флоя</td>\n",
       "      <td>2011-02-20</td>\n",
       "      <td>На что потратили аж 5000000?!</td>\n",
       "      <td>Bad</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\\n      Эх, как я пыталась настроить себя поло...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36579 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            part             movie_name  review_id         author       date  \\\n",
       "0         top250            Блеф (1976)      17144      Come Back 2011-09-24   \n",
       "1         top250            Блеф (1976)      17139        Stasiki 2008-03-04   \n",
       "2         top250            Блеф (1976)      17137       Flashman 2007-03-04   \n",
       "3         top250            Блеф (1976)      17135  Sergio Tishin 2009-08-17   \n",
       "4         top250            Блеф (1976)      17151        Фюльгья 2009-08-20   \n",
       "...          ...                    ...        ...            ...        ...   \n",
       "36586  bottom100  Цветок дьявола (2010)      25123     bestiya163 2010-09-23   \n",
       "36587  bottom100  Цветок дьявола (2010)      25192          Молка 2010-10-02   \n",
       "36588  bottom100  Цветок дьявола (2010)      25080          jetry 2010-09-16   \n",
       "36589  bottom100  Цветок дьявола (2010)      25088         Alkort 2010-09-16   \n",
       "36590  bottom100  Цветок дьявола (2010)      25149           Флоя 2011-02-20   \n",
       "\n",
       "                                                   title   grade3  grade10  \\\n",
       "0                                 Плакали наши денежки ©     Good     10.0   \n",
       "1                                                   None     Good      0.0   \n",
       "2                                                   None     Good     10.0   \n",
       "3      \" Черное, красное, ерунда это все. Выигрывает ...     Good      0.0   \n",
       "4                    «Он хотел убежать? Да! Блеф, блеф…»  Neutral      7.0   \n",
       "...                                                  ...      ...      ...   \n",
       "36586                                        Ой, ой, ой!      Bad      2.0   \n",
       "36587                          Молчаливый мужик на коне…      Bad      1.0   \n",
       "36588                      Это проявилось сегодня ночью.     Good      7.0   \n",
       "36589                                «Finita la comedia»      Bad      0.0   \n",
       "36590                      На что потратили аж 5000000?!      Bad      1.0   \n",
       "\n",
       "                                                 content  \n",
       "0      \\n\"Блеф» — одна из моих самых любимых комедий....  \n",
       "1      \\nАдриано Челентано продолжает радовать нас св...  \n",
       "2      \\nНесомненно, это один из великих фильмов 80-х...  \n",
       "3      \\nЭта фраза на мой взгляд отражает сюжет несом...  \n",
       "4      \\n- как пела Земфира, скорее всего, по соверше...  \n",
       "...                                                  ...  \n",
       "36586  \\n      Ну с чего бы начать… Давненько я не пи...  \n",
       "36587  \\n      Можно начать с того, что уже постер к ...  \n",
       "36588  \\n      Фильм производства России, поэтому мно...  \n",
       "36589  \\n      16 сентября на большие экраны вышел «м...  \n",
       "36590  \\n      Эх, как я пыталась настроить себя поло...  \n",
       "\n",
       "[36579 rows x 9 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../data/kinopoisk.jsonl'\n",
    "df = pd.read_json(file_path, lines=True)\n",
    "df = df.drop_duplicates(subset=['content'])\n",
    "df_sampled = df[df['grade3'] == 'Good'].sample(frac=0.825, random_state=42)\n",
    "df_remaining = df.drop(df_sampled.index)\n",
    "df_train = df_remaining[['content', 'grade3']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grade3\n",
       "Good       4769\n",
       "Bad        4751\n",
       "Neutral    4575\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['grade3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder = OrdinalEncoder(categories=[['Bad', 'Neutral', 'Good']])\n",
    "df_train['grade3'] = ordinal_encoder.fit_transform(df_train[['grade3']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['content'] = df_train['content'].apply(data_preprocessing)\n",
    "df_train = df_train[df_train['content'].str.strip().astype(bool)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['content'] = df['content'].apply(data_preprocessing)\n",
    "#df = df[df['content'].str.strip().astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus = [word for text in df['content'] for word in text.split()]\n",
    "#count_words = Counter(corpus)\n",
    "\n",
    "#sorted_words = count_words.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted_words = get_words_by_freq(sorted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../models/vocab_to_int.json\", \"r\", encoding=\"utf-8\") as json_file:\n",
    "    vocab_to_int = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_int = []\n",
    "for text in df_train['content']:\n",
    "\n",
    "    r = [vocab_to_int[word] for word in text.split() if vocab_to_int.get(word)]\n",
    "    reviews_int.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>grade3</th>\n",
       "      <th>Review len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>петь земфира скоро совершенно повод фильм челе...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>финансовый акула белль дюк иметь давний счеты ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>действие фильм разворачиваться примерно е год ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>должный поставлять против весь восхищаться воо...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>вор вор дубинка украсть эпиграф красный нить п...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  grade3  Review len\n",
       "4   петь земфира скоро совершенно повод фильм челе...     1.0         185\n",
       "7   финансовый акула белль дюк иметь давний счеты ...     1.0         139\n",
       "11  действие фильм разворачиваться примерно е год ...     2.0         119\n",
       "13  должный поставлять против весь восхищаться воо...     2.0         128\n",
       "15  вор вор дубинка украсть эпиграф красный нить п...     2.0         176"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_len = [len(x) for x in reviews_int]\n",
    "df_train['Review len'] = review_len\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя длина отзыва: 174.46 слов\n",
      "Медианная длина отзыва: 145.0 слов\n",
      "Максимальная длина отзыва: 1660 слов\n",
      "Минимальная длина отзыва: 3 слов\n"
     ]
    }
   ],
   "source": [
    "print(f\"Средняя длина отзыва: {df_train['Review len'].mean():.2f} слов\")\n",
    "print(f\"Медианная длина отзыва: {df_train['Review len'].median()} слов\")\n",
    "print(f\"Максимальная длина отзыва: {df_train['Review len'].max()} слов\")\n",
    "print(f\"Минимальная длина отзыва: {df_train['Review len'].min()} слов\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 111\n",
    "features = my_padding(reviews_int, SEQ_LEN, padding='right', truncating='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    features,\n",
    "    df_train['grade3'].to_numpy(),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df_train['grade3'].to_numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "valid_data = TensorDataset(torch.from_numpy(X_valid), torch.from_numpy(y_valid))\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
    "\n",
    "VOCAB_SIZE = len(vocab_to_int)+1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ConfigRNN:\n",
    "    vocab_size: int\n",
    "    device: str\n",
    "    n_layers: int\n",
    "    embedding_dim: int\n",
    "    hidden_size: int\n",
    "    seq_len: int\n",
    "    bidirectional: Union[bool, int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_config = ConfigRNN(\n",
    "    vocab_size=len(vocab_to_int) + 1,\n",
    "    device=DEVICE,\n",
    "    n_layers=4,\n",
    "    embedding_dim=32,\n",
    "    hidden_size=32,\n",
    "    seq_len=SEQ_LEN,\n",
    "    bidirectional=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "Layer               Kernel          Output       Params            FLOPs\n",
      "========================================================================\n",
      "0_embedding       [32, 21838]   [128, 111, 32]   698,816          14,208\n",
      "1_lstm                      -   [128, 111, 64]    92,160   8,009,220,096\n",
      "2_attention           [64, 1]    [128, 111, 1]        65       1,804,416\n",
      "3_clf.Linear_0       [64, 32]        [128, 32]     2,080         520,192\n",
      "4_clf.Tanh_1                -        [128, 32]         0          20,480\n",
      "5_clf.Dropout_2             -        [128, 32]         0               0\n",
      "6_clf.Linear_3        [32, 3]         [128, 3]        99          24,192\n",
      "========================================================================\n",
      "Total params: 793,220\n",
      "Trainable params: 793,220\n",
      "Non-trainable params: 0\n",
      "Total FLOPs: 8,011,603,584 / 8.01 GFLOPs\n",
      "------------------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 10.61\n",
      "Params size (MB): 3.03\n",
      "Estimated Total Size (MB): 13.75\n",
      "========================================================================\n"
     ]
    }
   ],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, rnn_conf=net_config) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_dim = rnn_conf.embedding_dim\n",
    "        self.hidden_size = rnn_conf.hidden_size\n",
    "        self.bidirectional = rnn_conf.bidirectional\n",
    "        self.n_layers = rnn_conf.n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(rnn_conf.vocab_size, self.embedding_dim)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding_dim,\n",
    "            hidden_size=self.hidden_size,\n",
    "            bidirectional=self.bidirectional,\n",
    "            batch_first=True,\n",
    "            num_layers=self.n_layers,\n",
    "        )\n",
    "        self.bidirect_factor = 2 if self.bidirectional else 1\n",
    "        self.attention = nn.Linear(self.hidden_size * self.bidirect_factor, 1)\n",
    "        self.clf = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size * self.bidirect_factor, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(32, 3)  # Три класса\n",
    "        )\n",
    "\n",
    "    def model_description(self):\n",
    "        direction = \"bidirect\" if self.bidirectional else \"onedirect\"\n",
    "        return f\"lstm_{direction}_{self.n_layers}\"\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        embeddings = self.embedding(x)\n",
    "        out, _ = self.lstm(embeddings)\n",
    "        attn_weights = torch.softmax(self.attention(out), dim=1)  # (batch_size, seq_len, 1)\n",
    "        context = torch.sum(out * attn_weights, dim=1)  # (batch_size, hidden_size * num_directions)\n",
    "        out = self.clf(context)\n",
    "        return out\n",
    "    \n",
    "net_config.bidirectional = True\n",
    "model_lstm = LSTMClassifier(net_config)\n",
    "model_lstm.to(device)\n",
    "tu.get_model_summary(model_lstm, sample_x.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_lstm = torch.optim.Adam(model_lstm.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'Accuracy': Accuracy(task='multiclass', num_classes=3).to(device),\n",
    "    'precision_metric': MulticlassPrecision(num_classes=3, average='macro').to(device),\n",
    "    'recall_metric': MulticlassRecall(num_classes=3, average='macro').to(device),\n",
    "    'f1_metric': MulticlassF1Score(num_classes=3, average='macro').to(device),\n",
    "    'averagepre_metric': MulticlassAveragePrecision(num_classes=3, average='macro').to(device)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "train_loss : 1.0941 val_loss : 1.0881\n",
      "Accuracy - train: 0.3581, val: 0.3679\n",
      "precision_metric - train: 0.3584, val: 0.2548\n",
      "recall_metric - train: 0.3581, val: 0.3665\n",
      "f1_metric - train: 0.3581, val: 0.2831\n",
      "averagepre_metric - train: 0.3628, val: 0.4123\n",
      "==================================================\n",
      "Сохранены лучшие веса модели после 1 эпохи с валид. лоссом: 1.0881\n",
      "Epoch 2\n",
      "train_loss : 1.0689 val_loss : 0.9929\n",
      "Accuracy - train: 0.4192, val: 0.5089\n",
      "precision_metric - train: 0.4198, val: 0.5009\n",
      "recall_metric - train: 0.4178, val: 0.5067\n",
      "f1_metric - train: 0.4144, val: 0.5006\n",
      "averagepre_metric - train: 0.4279, val: 0.5204\n",
      "==================================================\n",
      "Сохранены лучшие веса модели после 2 эпохи с валид. лоссом: 0.9929\n",
      "Epoch 3\n",
      "train_loss : 0.9665 val_loss : 0.9499\n",
      "Accuracy - train: 0.5301, val: 0.5366\n",
      "precision_metric - train: 0.5194, val: 0.5347\n",
      "recall_metric - train: 0.5270, val: 0.5328\n",
      "f1_metric - train: 0.5136, val: 0.5045\n",
      "averagepre_metric - train: 0.5364, val: 0.5603\n",
      "==================================================\n",
      "Сохранены лучшие веса модели после 3 эпохи с валид. лоссом: 0.9499\n",
      "Epoch 4\n",
      "train_loss : 0.9142 val_loss : 0.8978\n",
      "Accuracy - train: 0.5707, val: 0.5739\n",
      "precision_metric - train: 0.5574, val: 0.5623\n",
      "recall_metric - train: 0.5675, val: 0.5712\n",
      "f1_metric - train: 0.5540, val: 0.5642\n",
      "averagepre_metric - train: 0.5806, val: 0.5834\n",
      "==================================================\n",
      "Сохранены лучшие веса модели после 4 эпохи с валид. лоссом: 0.8978\n",
      "Epoch 5\n",
      "train_loss : 0.8601 val_loss : 0.8783\n",
      "Accuracy - train: 0.6015, val: 0.5831\n",
      "precision_metric - train: 0.5889, val: 0.5660\n",
      "recall_metric - train: 0.5985, val: 0.5792\n",
      "f1_metric - train: 0.5890, val: 0.5597\n",
      "averagepre_metric - train: 0.6225, val: 0.5980\n",
      "==================================================\n",
      "Сохранены лучшие веса модели после 5 эпохи с валид. лоссом: 0.8783\n",
      "Epoch 6\n",
      "train_loss : 0.8267 val_loss : 0.8625\n",
      "Accuracy - train: 0.6281, val: 0.5923\n",
      "precision_metric - train: 0.6160, val: 0.5794\n",
      "recall_metric - train: 0.6252, val: 0.5895\n",
      "f1_metric - train: 0.6164, val: 0.5805\n",
      "averagepre_metric - train: 0.6424, val: 0.6062\n",
      "==================================================\n",
      "Сохранены лучшие веса модели после 6 эпохи с валид. лоссом: 0.8625\n",
      "Epoch 7\n",
      "train_loss : 0.7960 val_loss : 0.8548\n",
      "Accuracy - train: 0.6423, val: 0.6016\n",
      "precision_metric - train: 0.6311, val: 0.5834\n",
      "recall_metric - train: 0.6394, val: 0.5981\n",
      "f1_metric - train: 0.6317, val: 0.5835\n",
      "averagepre_metric - train: 0.6678, val: 0.6135\n",
      "==================================================\n",
      "Сохранены лучшие веса модели после 7 эпохи с валид. лоссом: 0.8548\n",
      "Epoch 8\n",
      "train_loss : 0.7633 val_loss : 0.8608\n",
      "Accuracy - train: 0.6623, val: 0.6051\n",
      "precision_metric - train: 0.6509, val: 0.5958\n",
      "recall_metric - train: 0.6593, val: 0.6023\n",
      "f1_metric - train: 0.6508, val: 0.5944\n",
      "averagepre_metric - train: 0.6856, val: 0.6167\n",
      "==================================================\n",
      "Epoch 9\n",
      "train_loss : 0.7320 val_loss : 0.8563\n",
      "Accuracy - train: 0.6807, val: 0.6040\n",
      "precision_metric - train: 0.6706, val: 0.5920\n",
      "recall_metric - train: 0.6778, val: 0.6012\n",
      "f1_metric - train: 0.6712, val: 0.5939\n",
      "averagepre_metric - train: 0.7093, val: 0.6182\n",
      "==================================================\n",
      "Epoch 10\n",
      "train_loss : 0.7061 val_loss : 0.8618\n",
      "Accuracy - train: 0.6900, val: 0.6104\n",
      "precision_metric - train: 0.6801, val: 0.5992\n",
      "recall_metric - train: 0.6872, val: 0.6077\n",
      "f1_metric - train: 0.6806, val: 0.6012\n",
      "averagepre_metric - train: 0.7276, val: 0.6229\n",
      "==================================================\n",
      "Epoch 11\n",
      "train_loss : 0.6736 val_loss : 0.8879\n",
      "Accuracy - train: 0.7136, val: 0.5952\n",
      "precision_metric - train: 0.7062, val: 0.5887\n",
      "recall_metric - train: 0.7112, val: 0.5925\n",
      "f1_metric - train: 0.7073, val: 0.5873\n",
      "averagepre_metric - train: 0.7490, val: 0.6223\n",
      "==================================================\n",
      "Epoch 12\n",
      "train_loss : 0.6422 val_loss : 0.9300\n",
      "Accuracy - train: 0.7355, val: 0.5948\n",
      "precision_metric - train: 0.7284, val: 0.5881\n",
      "recall_metric - train: 0.7331, val: 0.5926\n",
      "f1_metric - train: 0.7288, val: 0.5881\n",
      "averagepre_metric - train: 0.7667, val: 0.6144\n",
      "==================================================\n",
      "Epoch 13\n",
      "train_loss : 0.6083 val_loss : 0.9465\n",
      "Accuracy - train: 0.7512, val: 0.5984\n",
      "precision_metric - train: 0.7453, val: 0.5856\n",
      "recall_metric - train: 0.7491, val: 0.5953\n",
      "f1_metric - train: 0.7460, val: 0.5870\n",
      "averagepre_metric - train: 0.7887, val: 0.6191\n",
      "==================================================\n",
      "Epoch 14\n",
      "train_loss : 0.5908 val_loss : 0.9439\n",
      "Accuracy - train: 0.7601, val: 0.6033\n",
      "precision_metric - train: 0.7551, val: 0.5907\n",
      "recall_metric - train: 0.7582, val: 0.6005\n",
      "f1_metric - train: 0.7558, val: 0.5932\n",
      "averagepre_metric - train: 0.7999, val: 0.6187\n",
      "==================================================\n",
      "Epoch 15\n",
      "train_loss : 0.5530 val_loss : 1.0093\n",
      "Accuracy - train: 0.7834, val: 0.5874\n",
      "precision_metric - train: 0.7789, val: 0.5768\n",
      "recall_metric - train: 0.7815, val: 0.5846\n",
      "f1_metric - train: 0.7793, val: 0.5783\n",
      "averagepre_metric - train: 0.8236, val: 0.6116\n",
      "==================================================\n",
      "Epoch 16\n",
      "train_loss : 0.5170 val_loss : 1.0327\n",
      "Accuracy - train: 0.8018, val: 0.5849\n",
      "precision_metric - train: 0.7979, val: 0.5713\n",
      "recall_metric - train: 0.8000, val: 0.5819\n",
      "f1_metric - train: 0.7982, val: 0.5744\n",
      "averagepre_metric - train: 0.8400, val: 0.6121\n",
      "==================================================\n",
      "Epoch 17\n",
      "train_loss : 0.4842 val_loss : 1.0731\n",
      "Accuracy - train: 0.8200, val: 0.5849\n",
      "precision_metric - train: 0.8172, val: 0.5864\n",
      "recall_metric - train: 0.8186, val: 0.5832\n",
      "f1_metric - train: 0.8175, val: 0.5844\n",
      "averagepre_metric - train: 0.8585, val: 0.6075\n",
      "==================================================\n",
      "Epoch 18\n",
      "train_loss : 0.4748 val_loss : 1.0764\n",
      "Accuracy - train: 0.8221, val: 0.5842\n",
      "precision_metric - train: 0.8195, val: 0.5811\n",
      "recall_metric - train: 0.8207, val: 0.5819\n",
      "f1_metric - train: 0.8199, val: 0.5805\n",
      "averagepre_metric - train: 0.8620, val: 0.6102\n",
      "==================================================\n",
      "Epoch 19\n",
      "train_loss : 0.4281 val_loss : 1.1470\n",
      "Accuracy - train: 0.8511, val: 0.5838\n",
      "precision_metric - train: 0.8492, val: 0.5860\n",
      "recall_metric - train: 0.8499, val: 0.5823\n",
      "f1_metric - train: 0.8494, val: 0.5838\n",
      "averagepre_metric - train: 0.8860, val: 0.6077\n",
      "==================================================\n",
      "Epoch 20\n",
      "train_loss : 0.3992 val_loss : 1.1963\n",
      "Accuracy - train: 0.8619, val: 0.5866\n",
      "precision_metric - train: 0.8602, val: 0.5829\n",
      "recall_metric - train: 0.8608, val: 0.5845\n",
      "f1_metric - train: 0.8603, val: 0.5829\n",
      "averagepre_metric - train: 0.8981, val: 0.6019\n",
      "==================================================\n",
      "Epoch 21\n",
      "train_loss : 0.3660 val_loss : 1.2530\n",
      "Accuracy - train: 0.8798, val: 0.5835\n",
      "precision_metric - train: 0.8785, val: 0.5813\n",
      "recall_metric - train: 0.8788, val: 0.5814\n",
      "f1_metric - train: 0.8785, val: 0.5807\n",
      "averagepre_metric - train: 0.9130, val: 0.6009\n",
      "==================================================\n",
      "Epoch 22\n",
      "train_loss : 0.3517 val_loss : 1.3043\n",
      "Accuracy - train: 0.8841, val: 0.5881\n",
      "precision_metric - train: 0.8828, val: 0.5819\n",
      "recall_metric - train: 0.8832, val: 0.5858\n",
      "f1_metric - train: 0.8829, val: 0.5832\n",
      "averagepre_metric - train: 0.9166, val: 0.5976\n",
      "==================================================\n",
      "Ранняя остановка на 22 эпохе\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses, train_metrics, val_metrics, rnn_time, predicts = train3(\n",
    "    epochs=100,\n",
    "    model=model_lstm,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    optimizer=optimizer_lstm,\n",
    "    criterion=criterion,\n",
    "    metrics=metrics,\n",
    "    rnn_conf=net_config,\n",
    "    patience=15,\n",
    "    save_path=f'../models/best_{type(model_lstm).__name__}_weights.pth',\n",
    "    attention=True,\n",
    "    multiclass=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch 7</th>\n",
       "      <th>Epoch 9</th>\n",
       "      <th>Epoch 10</th>\n",
       "      <th>Epoch 8</th>\n",
       "      <th>Epoch 6</th>\n",
       "      <th>Epoch 5</th>\n",
       "      <th>Epoch 11</th>\n",
       "      <th>Epoch 4</th>\n",
       "      <th>Epoch 12</th>\n",
       "      <th>Epoch 14</th>\n",
       "      <th>Epoch 3</th>\n",
       "      <th>Epoch 13</th>\n",
       "      <th>Epoch 2</th>\n",
       "      <th>Epoch 15</th>\n",
       "      <th>Epoch 16</th>\n",
       "      <th>Epoch 17</th>\n",
       "      <th>Epoch 18</th>\n",
       "      <th>Epoch 1</th>\n",
       "      <th>Epoch 19</th>\n",
       "      <th>Epoch 20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_loss</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_loss</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_Accuracy</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_precision_metric</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_recall_metric</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_f1_metric</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_averagepre_metric</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_Accuracy</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_precision_metric</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_recall_metric</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_f1_metric</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_averagepre_metric</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Epoch 7  Epoch 9  Epoch 10  Epoch 8  Epoch 6  \\\n",
       "train_loss                  0.80     0.73      0.71     0.76     0.83   \n",
       "val_loss                    0.85     0.86      0.86     0.86     0.86   \n",
       "train_Accuracy              0.64     0.68      0.69     0.66     0.63   \n",
       "train_precision_metric      0.63     0.67      0.68     0.65     0.62   \n",
       "train_recall_metric         0.64     0.68      0.69     0.66     0.63   \n",
       "train_f1_metric             0.63     0.67      0.68     0.65     0.62   \n",
       "train_averagepre_metric     0.67     0.71      0.73     0.69     0.64   \n",
       "val_Accuracy                0.60     0.60      0.61     0.61     0.59   \n",
       "val_precision_metric        0.58     0.59      0.60     0.60     0.58   \n",
       "val_recall_metric           0.60     0.60      0.61     0.60     0.59   \n",
       "val_f1_metric               0.58     0.59      0.60     0.59     0.58   \n",
       "val_averagepre_metric       0.61     0.62      0.62     0.62     0.61   \n",
       "\n",
       "                         Epoch 5  Epoch 11  Epoch 4  Epoch 12  Epoch 14  \\\n",
       "train_loss                  0.86      0.67     0.91      0.64      0.59   \n",
       "val_loss                    0.88      0.89     0.90      0.93      0.94   \n",
       "train_Accuracy              0.60      0.71     0.57      0.74      0.76   \n",
       "train_precision_metric      0.59      0.71     0.56      0.73      0.76   \n",
       "train_recall_metric         0.60      0.71     0.57      0.73      0.76   \n",
       "train_f1_metric             0.59      0.71     0.55      0.73      0.76   \n",
       "train_averagepre_metric     0.62      0.75     0.58      0.77      0.80   \n",
       "val_Accuracy                0.58      0.60     0.57      0.59      0.60   \n",
       "val_precision_metric        0.57      0.59     0.56      0.59      0.59   \n",
       "val_recall_metric           0.58      0.59     0.57      0.59      0.60   \n",
       "val_f1_metric               0.56      0.59     0.56      0.59      0.59   \n",
       "val_averagepre_metric       0.60      0.62     0.58      0.61      0.62   \n",
       "\n",
       "                         Epoch 3  Epoch 13  Epoch 2  Epoch 15  Epoch 16  \\\n",
       "train_loss                  0.97      0.61     1.07      0.55      0.52   \n",
       "val_loss                    0.95      0.95     0.99      1.01      1.03   \n",
       "train_Accuracy              0.53      0.75     0.42      0.78      0.80   \n",
       "train_precision_metric      0.52      0.75     0.42      0.78      0.80   \n",
       "train_recall_metric         0.53      0.75     0.42      0.78      0.80   \n",
       "train_f1_metric             0.51      0.75     0.41      0.78      0.80   \n",
       "train_averagepre_metric     0.54      0.79     0.43      0.82      0.84   \n",
       "val_Accuracy                0.54      0.60     0.51      0.59      0.58   \n",
       "val_precision_metric        0.53      0.59     0.50      0.58      0.57   \n",
       "val_recall_metric           0.53      0.60     0.51      0.58      0.58   \n",
       "val_f1_metric               0.50      0.59     0.50      0.58      0.57   \n",
       "val_averagepre_metric       0.56      0.62     0.52      0.61      0.61   \n",
       "\n",
       "                         Epoch 17  Epoch 18  Epoch 1  Epoch 19  Epoch 20  \n",
       "train_loss                   0.48      0.47     1.09      0.43      0.40  \n",
       "val_loss                     1.07      1.08     1.09      1.15      1.20  \n",
       "train_Accuracy               0.82      0.82     0.36      0.85      0.86  \n",
       "train_precision_metric       0.82      0.82     0.36      0.85      0.86  \n",
       "train_recall_metric          0.82      0.82     0.36      0.85      0.86  \n",
       "train_f1_metric              0.82      0.82     0.36      0.85      0.86  \n",
       "train_averagepre_metric      0.86      0.86     0.36      0.89      0.90  \n",
       "val_Accuracy                 0.58      0.58     0.37      0.58      0.59  \n",
       "val_precision_metric         0.59      0.58     0.25      0.59      0.58  \n",
       "val_recall_metric            0.58      0.58     0.37      0.58      0.58  \n",
       "val_f1_metric                0.58      0.58     0.28      0.58      0.58  \n",
       "val_averagepre_metric        0.61      0.61     0.41      0.61      0.60  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = train_losses, val_losses, train_metrics, val_metrics\n",
    "df_metrics = logs_dict_multi_metrics(logs)\n",
    "val_losses = df_metrics.loc['val_loss']\n",
    "sorted_val_losses = val_losses.sort_values()\n",
    "top_20_epochs = sorted_val_losses.index[:20]\n",
    "df_top_20 = df_metrics[top_20_epochs]\n",
    "df_top_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "if 'фильм' in vocab_to_int:\n",
    "    print(vocab_to_int['фильм'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech = df['content'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эта фраза на мой взгляд отражает сюжет несомненно прекрасного фильма. Есть в ней один человек — Феликс, молодой, экстравагантный, хитрый и, одновременно бывающий очень серьезным. Нужно ли кому-то говорить что в рулетке только одно зеро… А есть все остальные, разделенные по сути на две команды. Они также очень находчивы, но в итоге оказывается что чего-то им не хватает, может быть простоты, может этой самой находчивости. \n",
      "\n",
      "Разумеется фильм далек от философии, или чего бы то ни было высокого. Фильм для того чтобы повеселиться, и его главная задача — смешить зрителей на протяжении всего фильма — выполнена на 5+. Не буду говорить о талантливых артистах, один лишь список актеров позволит вам понять что с ними в этом фильме все хорошо. \n",
      "\n",
      "Хотелось лишь сказать о самых больших плюсах фильма. Это естественно харизматичные актеры, Энтони Куинн и Челентано просто идеально вписались в эти роли. Великолепные шутки, очень ненавязчивые, что оставляет лишь приятное впечатление. Во всяком случае то, что фильм стоит посмотреть только ради этих двух вещй гарантированно. \n",
      "\n",
      "Поэтому всем кто еще не видел этой кинокартины рекомендую обязательно посмотреть!\n"
     ]
    }
   ],
   "source": [
    "print(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(reviews_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение всей модели\n",
    "torch.save(model_lstm, 'model_lstm.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказанный класс: Neutral С вероятностью: 0.91\n"
     ]
    }
   ],
   "source": [
    "def l_predict_class(model, text, preprocess_fn, padding, seq_len, vocabulary, device='cuda'):\n",
    "    model.to(device)\n",
    "    model.eval()  # Устанавливаем модель в режим оценки\n",
    "    \n",
    "    # Предобработка текста\n",
    "    text = preprocess_fn(text)\n",
    "    text_list = [vocabulary[word] for word in text if word in vocabulary]\n",
    "\n",
    "    # Пэддинг и преобразование в тензор\n",
    "    padded_text = padding([text_list], seq_len, padding='right', truncating='right')[0]\n",
    "    text_tensor = torch.tensor(padded_text, dtype=torch.long).to(device).unsqueeze(0)\n",
    "\n",
    "    # Прогон через модель\n",
    "    with torch.no_grad():  # Отключаем градиенты\n",
    "        output = model(text_tensor)  # Получаем только один выходной тензор\n",
    "    \n",
    "    # Преобразуем логиты в вероятности\n",
    "    probabilities = F.softmax(output, dim=1)\n",
    "    \n",
    "    # Получаем предсказанный класс и вероятность\n",
    "    predicted_class = probabilities.argmax(dim=1).item()\n",
    "    confidence = probabilities[0, predicted_class].item()  # Вероятность предсказанного класса\n",
    "    \n",
    "    # Преобразуем числовой класс в строковый\n",
    "    pred_dict = {\n",
    "        0: 'Bad',\n",
    "        1: 'Neutral',\n",
    "        2: 'Good'\n",
    "    }\n",
    "    predicted_label = pred_dict.get(predicted_class, \"Unknown\")\n",
    "    \n",
    "    return predicted_label, confidence\n",
    "# Вызов функции\n",
    "class_label, prob = l_predict_class(\n",
    "    model_lstm,\n",
    "    speech,\n",
    "    preprocess_fn=data_preprocessing,\n",
    "    padding=my_padding,\n",
    "    seq_len=SEQ_LEN,\n",
    "    vocabulary=vocab_to_int,\n",
    "    device='cpu'\n",
    ")\n",
    "print(\"Предсказанный класс:\", class_label, 'С вероятностью:', round(prob, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
